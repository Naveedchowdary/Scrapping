import os
import pysftp
import random
#import zipfile
from time import sleep
from threading import Lock
from openpyxl import Workbook
from datetime import datetime
from selenium import webdriver
from openpyxl import load_workbook
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.alert import Alert
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import NoAlertPresentException
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException

path_to_save_pdf = 'D:\\Downloaded County Documents\\AL-MADISON'

initiation_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
print("Initiation Time: ", initiation_time)

excel_write_lock = Lock()

chrome_options = Options()

chrome_options.add_experimental_option('prefs', {
    'plugins.always_open_pdf_externally': True,  # Give True to download & Give False to view
    'download.default_directory': path_to_save_pdf
})

excel_file = 'C:\\Scrappers\\County_dates.xlsx'  # Change the file extension to .xlsx
wb = load_workbook(excel_file)
ws = wb.active

counties = []
start_dates = []
end_dates = []
total_downloaded = []  # Add a list to store the total downloaded records

target_county = 'AL-MADISON'

# Assuming that the first row contains headers
headers = [cell.value for cell in ws[1]]

# Find the column indexes for 'County Name', 'Start Date', 'End Date', and 'Total_documents'
county_name_index = headers.index('County')
start_date_index = headers.index('Start_date')
end_date_index = headers.index('End_date')
total_documents_index = headers.index('Total_downloaded')

for row in ws.iter_rows(min_row=2):
    county_name = row[county_name_index].value
    if county_name == target_county:
        start_date = row[start_date_index].value
        end_date = row[end_date_index].value

        if start_date and end_date:
            counties.append(county_name)
            start_dates.append(start_date)  # Format date as needed
            end_dates.append(end_date)  # Format date as needed
            total_downloaded.append(row[total_documents_index].value)  # Append existing total downloaded records

if not counties:
    print("No valid data found in the Excel file.")
    exit()

d1 = start_date.strftime('%m/%d/%Y')
d2 = end_date.strftime('%m/%d/%Y')

browser = webdriver.Chrome(options=chrome_options)

url = "https://madisonprobate.countygovservices.com/Search/SearchType?key=all_books"
browser.get(url)
browser.maximize_window()

# log in
sleep_duration = random.uniform(8, 10)
sleep(sleep_duration)
mail = browser.find_element(By.XPATH, "//input[@id='email']").send_keys('yibikek815@datakop.com')
sleep(sleep_duration)
password = browser.find_element(By.XPATH, "//input[@id='password']").send_keys('yibikek815@123')
sleep(sleep_duration)
keep_remember = browser.find_element(By.XPATH, "//input[@id='rememberMe']").click()
sleep(sleep_duration)
sign_in = browser.find_element(By.XPATH, "//button[contains(text(),'Sign in')]").click()
sleep_duration = random.uniform(5, 7)
sleep(sleep_duration)

try:
    read = WebDriverWait(browser, 30).until(EC.element_to_be_clickable((By.XPATH, "//input[@id='termsacceptedcb']")))
    read.click()
    sleep_duration = random.uniform(2, 4)
    sleep(sleep_duration)
    cont = browser.find_element(By.XPATH, "//input[@value='Continue']").click()
    sleep_duration = random.uniform(2, 4)
    sleep(sleep_duration)
except Exception as e:
    pass


def documents(docu_type):
    # selecting instrument type
    sleep_duration = random.uniform(8, 12)
    sleep(sleep_duration)
    browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    search_but = browser.find_element(By.XPATH, "//div[contains(text(),'Search')]/i")
    browser.execute_script("arguments[0].scrollIntoView();", search_but)
    sleep_duration = random.uniform(2, 4)
    sleep(sleep_duration)

    drop_down = browser.find_element(By.XPATH, "//*[@id='instrumenttypecombo']/div/div[3]/input")
    browser.execute_script("arguments[0].click();", drop_down)
    sleep_duration = random.uniform(3, 5)
    sleep(sleep_duration)

    if docu_type == 'Mortgage':
        print('About Mortgage :')
        document = browser.find_element(By.XPATH, "//li[contains(text(),'Mortgage (MORTGAGE)')][4]").click()
    else:
        print('About Deed :')
        document = browser.find_element(By.XPATH, "//li[contains(text(),'Deed (DEED)')][3]").click()

    sleep_duration = random.uniform(3, 5)
    sleep(sleep_duration)
    # Recording date
    input_start_date = browser.find_element(By.XPATH, "//input[@id='startdatepicker']")
    input_start_date.click()
    sleep(sleep_duration)
    input_start_date.send_keys(d1)
    sleep(sleep_duration)
    
    # Click to search  records
    browser.execute_script("window.scrollBy(0,100)", "")
    sleep(sleep_duration)
    search_button = browser.find_element(By.XPATH, "//div[contains(text(),'Search')]/i").click()
    sleep_duration = random.uniform(4, 6)
    sleep(sleep_duration)

    try:
        alert = browser.find_element(By.XPATH, "//button[text()='OK']")
        if alert.is_displayed():
            alert.click()
            sleep(sleep_duration)
            search_button = browser.find_element(By.XPATH, "//div[contains(text(),'Search')]/i").click()
            sleep(sleep_duration)
    except Exception as e:
        pass

    sleep_duration = random.uniform(8, 12)
    sleep(sleep_duration)

    # Counting the total pages & Counting the total documents & How much documents it's downloaded
    total_pages = 0
    total = 0
    p = 0
    s = 0
    while True:
        sleep_duration = random.uniform(5, 8)
        sleep(sleep_duration)
        p = p + 1
        print('Scrapping page:', p)
        element_count = len(browser.find_elements(By.XPATH, "//*[@id='gridResults']"))
        total_pages += element_count

        links = browser.find_elements(By.XPATH, "//button[contains(text(),'VIEW')]")
        if len(links) != 0:
            print('Total records in page', p, ':', len(links))
            total = total + len(links)
            d = 0

            for view in links:
                browser.execute_script("arguments[0].scrollIntoView(true);", view)
                parent_handle = browser.current_window_handle
                sleep_duration = random.uniform(1, 3)
                sleep(sleep_duration)
                view.click()
                sleep_duration = random.uniform(9, 12)
                sleep(sleep_duration)
                all_handles = browser.window_handles
                for handle in all_handles:
                    if handle != parent_handle:
                        browser.switch_to.window(handle)
                        sleep_duration = random.uniform(18, 21)
                        sleep(sleep_duration)
                        browser.execute_script("window.scrollTo(0,150);")
                        sleep_duration = random.uniform(3, 5)
                        sleep(sleep_duration)
                        download_instrument = WebDriverWait(browser, 20).until(
                            EC.element_to_be_clickable((By.XPATH, "//div[contains(text(),'Download Instrument')]")))
                        download_instrument.click()
                        sleep_duration = random.uniform(7,9)
                        sleep(sleep_duration)
                        download = WebDriverWait(browser, 20).until(EC.element_to_be_clickable(
                            (By.XPATH, "//div[@class='btn btn-primary'][text()='Download']")))
                        download.click()
                        d += 1
                        sleep_duration = random.uniform(30, 35)
                        sleep(sleep_duration)
                        browser.close()

                browser.switch_to.window(parent_handle)
                sleep_duration = random.uniform(4, 6)
                sleep(sleep_duration)

            sleep_duration = random.uniform(4, 6)
            sleep(sleep_duration)
            print('Successfully downloaded', d, 'documents in page', p)

        else:
            d = 0
            print(f'{docu_type} documents are not available')

        s += d
        sleep_duration = random.uniform(4, 6)
        sleep(sleep_duration)
        browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        sleep_duration = random.uniform(3, 5)
        sleep(sleep_duration)
        try:
            next_page = browser.find_element(By.XPATH,
                                             "//span[@class='ui-iggrid-nextpagelabel'][text()='Next']").click()
            sleep_duration = random.uniform(4, 6)
            sleep(sleep_duration)
        except Exception as e:
            break
        browser.execute_script("window.scrollTo(0,0);")

    print('Total Pages: ', total_pages)
    print('Total documents:', total)
    print('Total downloaded documents:', s)

    write_to_excel(target_county, s, total)

    sleep_duration = random.uniform(3, 5)
    sleep(sleep_duration)
    back = browser.find_element(By.XPATH, "//a[@id='backtosearchbutton']")
    browser.execute_script("arguments[0].scrollIntoView(true);", back)
    sleep_duration = random.uniform(3, 5)
    sleep(sleep_duration)
    back.click()
    sleep_duration = random.uniform(6, 8)
    sleep(sleep_duration)
    browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    sleep_duration = random.uniform(3, 5)
    sleep(sleep_duration)
    reset = browser.find_element(By.XPATH, "//div[contains(text(),'Reset')]").click()
    sleep(sleep_duration)

def write_to_excel(target_county, total_downloaded, total_recs):
    # Acquire the lock before writing to the Excel file
    with excel_write_lock:
        try:
            # Load the existing workbook
            wb = load_workbook(excel_file)
            ws = wb.active

            # Find the column indexes for headers
            headers = [cell.value for cell in ws[1]]
            total_documents_index = headers.index('Total_downloaded') + 1  # Add 1 for 1-based indexing
            total_recs_index = headers.index('Total_records') + 1
            
            # Find the row corresponding to the target county
            for row in ws.iter_rows(min_row=2, max_row=ws.max_row):
                if row[0].value == target_county:  # Assuming target county is in the first column
                    # Update the 'Total_documents' column with the total downloaded documents
                    row[total_documents_index - 1].value = total_downloaded  # Subtract 1 for 0-based indexing
                    row[total_recs_index - 1].value = total_recs  # Subtract 1 for 0-based indexing
                    break

            # Save the workbook
            wb.save(excel_file)

        finally:
            # Release the lock after writing to the Excel file
            pass

documents('Mortgage')

# documents('Deed')

browser.quit()

end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
print("End Time: ", end_time)
